---
title: "Eindopdracht groep 47"
author: "Mitchel Eilerts en Lucas Mooij"
date: "2025-01-17"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
#install.packages("ggrepel")
library(ggrepel)
library(scales)
library(tsibble)
library(dplyr)
library(fpp3)
library(fable)
library(ggplot2)
```



```{r TIJD}
files <- read.csv("filedata.csv", sep =";")
```

```{r TIJD}
#Kijken naar de dataset
sum(is.na(files))
max(files$duurMinuten)
min(files$duurMinuten)
str(files)
```
Voor het voorspellen van de filedruk is de belangrijkste variabele de variabele "zwaarteKmMin". Nu is nog wel voor elke file apart de filesterkte aangegeven. Dit moet nog opgezet worden naar de dagelijse filezwaarte.

```{r TIJD}
#Numerieke waarden maaken van de filezwaarte en de begindatum nemen van de file in juist dataformaat
files$zwaarteKmMin <- as.numeric(files$zwaarteKmMin)
files$BeginDatum <- as.Date(files$BeginDatum)

#De sommatie van alle files nemen per dag
filedag <- aggregate(zwaarteKmMin ~ BeginDatum, data = files, FUN = sum)

#Een reeks aangemaakt die alle data heeft van de periode waarin is gemeten. Dit is gedaan zodat deze gemerged kan worden met
#De filedag tijdreeks. Deze mist nu dagen waarin geen file was. 
alle_datums <- data.frame(BeginDatum = seq(min(as.Date(files$BeginDatum)), 
                                           max(as.Date(files$BeginDatum)), 
                                           by = "day"))

#De reeksen mergen. Bij het mergen onstaan NA waarden op dagen waar geen file was. Maar nu heeft de tijdreeks wel
#alle data van de meetperiode
filedag <- merge(alle_datums, filedag, by = "BeginDatum", all.x = TRUE)
#0 invullen bij alle NA sinds er geen file was die dag, anders zou die datum wel hebben gestaan in het orginele filebestand

filedag$zwaarteKmMin[is.na(filedag$zwaarteKmMin)] <- 0
# de tijdreeks kolommen fijnere namen geven om mee te werken
colnames(filedag) <- c("Datum", "Zwaarte")
filedag <- filedag %>%
  as_tsibble(index = Datum)
filedag
```

```{r}

```



```{r fig.width=20, fig.height=6}
#autoplot maken van de tijdreeks
filedag %>%
  ggplot(aes(x = Datum, y = Zwaarte / 60)) + #Er is gedeed door 60, hierdoor is filezwarte niet meer in km * minuut, maar in km* uur
  geom_line(color = "darkgreen") +  # Groene lijn
  labs(
    title = "Totale filezwaarte per dag in aantal km maal aantal uren",
    x = "Jaar",
    y = "Aantal km maar aantal uren file"
  ) +
  scale_x_date(
    breaks = seq(from = as.Date("2000-01-01"), to = as.Date("2024-01-01"), by = "1 year"),
    labels = scales::date_format("%Y"),
    limits = c(as.Date("2000-01-01"), as.Date("2024-01-01"))
  ) +
  coord_cartesian(ylim = c(0, 3500)) +
  theme_minimal() +  # Zelfde achtergrond als vorige plots
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1, size = 12),  # Grotere x-as labels
    axis.text.y = element_text(size = 12),                         # Grotere y-as labels
    axis.title.x = element_text(size = 14),                        # Grotere x-as titel
    axis.title.y = element_text(size = 14),                        # Grotere y-as titel
    plot.title = element_text(size = 16, hjust = 0.5)              # Grotere plot titel, gecentreerd
  )
```

```{r}
file_decomp <- filedag %>%model( STL(Zwaarte ~ trend(window = 366) +season(window = "periodic"), robust = TRUE) ) %>% components()

file_decomp_2023 <- filedag %>%
  filter(Datum >= as.Date('2023-01-07') & Datum < as.Date('2023-04-01')) %>%
  model( STL(Zwaarte ~ trend(window = 15) +season(window = "periodic"), robust = TRUE) ) %>% components()
```



```{r fig.width=20, fig.height=6}
#Er wordt een decompositie van de tijdreeks gemaakt zodat kan worden gekeken naar de losse tijdreekscomponenten 
#en hier conclusies over kunnen worden getrokken.

file_decomp %>%
  select(Datum, season_year, trend) %>%  # Selecteer de trend en seizoenscomponent
  pivot_longer(
    cols = c(season_year, trend), 
    names_to = "Component", 
    values_to = "Value"
  ) %>%
  ggplot(aes(x = Datum, y = Value, color = Component)) +
  geom_line() +
  labs(
    title = "Trend en jaarlijkse seizoenscomponent van dagelijkse filezwaarte",
    x = "Jaar",
    y = "Filezwaarte"
  ) +
  scale_x_date(
    breaks = seq(from = as.Date("2000-01-01"), to = as.Date("2024-01-01"), by = "1 year"),
    labels = scales::date_format("%Y"),
    limits = c(as.Date("2000-01-01"), as.Date("2024-01-01"))
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    plot.title = element_text(size = 16, hjust = 0.5)
  ) +
  scale_color_manual(
    values = c("blue", "orange"), 
    name = "Component", 
    labels = c("Jaarlijks seizoenscomponent", "Trend")  # Aangepaste labels voor de legenda
  )
```

```{r fig.width=20, fig.height=6}
file_decomp_2023 %>%
  select(Datum, season_week, trend) %>%  # Selecteer de seizoens- en trendcomponent
  pivot_longer(
    cols = c(season_week, trend), 
    names_to = "Component", 
    values_to = "Value"
  ) %>%
  ggplot(aes(x = Datum, y = Value, color = Component)) +
  geom_line() +
  labs(
    title = "Trend en wekelijkse seizoenscomponent van dagelijkse filezwaarte tussen 7 januari en 1 april 2023",
    x = "Datum",
    y = "Filezwaarte"
  ) +
  scale_x_date(
    date_breaks = "1 week",         # Zet een label voor elke week
    date_labels = "%Y-%m-%d",      # Formatteer als 'jaar-maand-dag'
    limits = c(as.Date("2023-01-07"), as.Date("2023-04-01")) # Beperk x-as tot specifiek bereik
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    plot.title = element_text(size = 16, hjust = 0.5)
  ) +
  scale_color_manual(
    values = c("blue", "orange"), 
    name = "Component", 
    labels = c("Wekelijkse Seizoenscomponent", "Trend")  # Aangepaste labels voor de legenda
  )


```

1b)   De trend is stijgend tot het jaar 2008, vervolgens dalend tot 2014 en stijgt weer tot 2020. Daarna is er een flinke daling zichtbaar in het jaar 2020. Daarna stijgt het weer. Verder is er ook een overduidelijk seizoenscomponent te zien, waarbij het begin en het einde van het jaar laag is, en in het voorjaar en het najaar hoog is. 

Vervolgens is er gekeken naar een subset van de tijdreeks, namelijk van de eerste 13 weken van 2023 met uitzondering van de eerste week, waarin het nog kerstvakantie was. Dit is gedaan om beter het verloop per week te zien. Hierdoor kunnen we concluderen dat er nog een tweede seizoenscomponent is, die weekelijks is. In de STL decompostite is het weekend blauw gemarkeerd om beter de weken te zien. Dan is te zien dat de dinsdagen en donderdagen steeds het hoogst zijn, maandagen, woensdagen en vrijdagen zijn nog steeds druk maar lager en de weekenden zijn het laagst.

1c)   Er wordt onderscheid gemaakt in gebeurtenissen die invloed hadden voor 1 of enkele dagen en gebeurtenissen voor de langere termijn.
        Er zijn drie pieken van filezwaarte boven de 3000 uur maal kilometer. 
          1. In november 2005 was er een zeer zware sneeuwstorm die tot ongekende files leidde.
          2. December 2010 was een zeer koude maand en halverwege de maand viel een grote hoeveelheid sneeuw in de randstad. De piek was iets lager dan de piek in 2005 ondanks dat er              meer sneeuw viel, maar omdat deze gebeurtenis plaatsvond in december, waar veel mensen al op vakantie waren, viel de piek naar verwachting iets lager uit.
          3. In februari 2012 viel er ook veel sneeuw in Noord-Holland, Utrecht en Friesland. 
        Er waren in deze periode ook gebeurtenissen die invloed hebben op de langere termijn. De twee belangrijkste worden benoemd.
          1. In 2008 begon de financiële crisis waardoor de welvaart daalde. Daarom nam zeer waarschijnlijk ook het aantal files over de jaren af in plaats van toe.
          2. In 2020 brak het coronavirus uit, waardoor de overheid de bevolking sterk aanraadde om thuis te werken. Ook werden meerdere lockdowns van kracht. Dit leidde tot een flinke maar wel tijdelijk daling van de filezwaarte in Nederland.
        

```{r TIJD}
#Er wordt gekeken naar de standaarddiviatie, de kwartielen en de interkwartielafstand.
#Dit wordt gedaan om inzicht te krijgen in de verdeling van de filesterkte. Dit zou kunnen helpen 
#met het bepalen of de eis van RWS van er maximaal 20000 naast zitten te hoog, te laag of goed is
sd(filedag$Zwaarte)
quantile(filedag$Zwaarte)
IQR(filedag$Zwaarte)
```


```{r TIJD}
#Er wordt ook gekeken naar deze waarden nadat de uitbijters verwijderd zijn, om te kijken hoe deze zijn aangepast.
#Vaak kan je met het verwijderen van uitbijters betere voorspellingen maken. Daarom wordt er hier naar gekeken.
file_outliers <- file_decomp %>%
  filter(remainder %in% boxplot.stats(file_decomp$remainder, coef = 3)$out)
file_cleaned <- file_decomp %>%
  filter(!remainder %in% file_outliers$remainder)
sd_cleaned <- sd(file_cleaned$remainder)
quantiles_cleaned <- quantile(file_cleaned$remainder)
iqr_cleaned <- IQR(file_cleaned$remainder)
sd_cleaned
quantiles_cleaned
iqr_cleaned

```

```{r TIJD}
#Er is een periode gekozen om te trainen en testen. Deze data zijn gekozen omdat deze zich vrij dichtbij de huidige dag bevinden. Die data zijn het relevants, sinds de toekomst altijd wordt voorspeld. Dat zal dus meer met deze data overeen komen.
#Wel zijn alle dagen na de Coronapandemie zodat de pandemie veel minder effect zal hebben op de voorspellingen.
file_train <- filedag %>% filter(Datum >= as.Date('2022-01-10') & Datum < as.Date('2023-02-20'))
file_test <- filedag %>% filter(Datum >= as.Date('2023-02-20') & Datum < as.Date('2023-03-20'))
```


```{r TIJD}
#Er worden meerdere trainsets aangemaakt zodat je er meermaals over de data heen getraind kan worden
file_train_sets <- file_train %>% stretch_tsibble(.init = 29, .step = 1, .id='id')

#Als eerst wordt gekeken naar de simpele modellen. Er wordt van uitgegaan dat deze de slechtste resultaten zullen leveren.
file_fit <- file_train_sets %>%
  model(
    Drift = RW(Zwaarte ~ drift()),
    Mean = MEAN(Zwaarte),
    Naive = NAIVE(Zwaarte),
    SNaive = SNAIVE(Zwaarte)
    )

#Er worden forecasts gemaakt voor 4 weken. Dit gedaan om te kijken of ze nog zo ver kunnen voorspellen
file_fc <- file_fit %>% forecast(h = 28)

file_fc <- file_fc %>%
  left_join(file_test, by = "Datum")

#De eis van RWS is dat de voorspellingen er maximaal 20000 naast mogen zitten. 
#Hierom is ook gekeken daar de gemiddelde absolute fout.
file_MAE <- file_fc %>%
  as_tibble() %>%
  group_by(id, .model) %>%
  summarize(MAE = mean(abs(.mean - Zwaarte.y), na.rm = TRUE), .groups = "drop")

file_minMAE <- file_MAE %>%
  group_by(.model) %>%
  slice_min(MAE, n = 1, with_ties = FALSE) %>%
  ungroup()

file_minMAE <- file_minMAE %>%
  left_join(file_train_sets, by = "id")

file_minMAE %>%
  group_by(.model) %>%
  filter(Datum == min(Datum)) %>%
  summarize(
    Model = .model,
    startmoment = min(Datum),
    MAE = min(MAE)
  )
```
2a) de standaarddeviatie van de data is ruim 29000. 20000 is daarom een aardig grote bandbreedte om voorspellingen te maken. Waneer de 37 uitbijters worden verwijderd, is de standaarddeviatie gedaald naar minder dan 20000.
Ook als wordt gekeken naar de MAE van de simpele modellen ligt deze behoorlijk onder de 20000.
Dus het is is een relatief grote brandbreedte


```{r fig.width=20}
#Er wordt gekeken naar de partiële plot van de trainingsdata. Dit is gedaan zodat de er een schatting kan worden gemaakt 
#voor welke parameters de arima modellen zouden kunnen hebben.
file_train %>% gg_tsdisplay(Zwaarte, plot_type = 'partial', lag_max = 77)
```

```{r TIJD}
file_train %>%
  autoplot()
frequency(file_train$Zwaarte)
file_train <- file_train %>%
  mutate(Zwaarte = ts(Zwaarte, frequency = 7))
```

```{r TIJD}
#kan deze weg? hij staat ook boven maar breder?
file_train %>% gg_tsdisplay(Zwaarte, plot_type = 'partial', lag_max = 77)
```

```{r TIJD}
#Ook wordt gekeken naar de unit roots, zodat bekend is hoevaak gedifferentieerd moet worden
file_train %>% features(Zwaarte, c(unitroot_ndiffs, unitroot_nsdiffs))
```


```{r TIJD}
#Beperk parametercombinaties
parameters <- expand_grid(p=0:2, d = 0:1, q = 0:2, P = 0:2, D = 0:1, Q = 0:2)
parameters <- parameters %>% mutate(MAE = NA)

#Een gridsearch wordt uitgevoerd voor de gekozen parametercombinatie
for (i in 1:nrow(parameters)){
  tryCatch({
    parameters[i, "MAE"] <- file_train %>%
      model(
        ARIMA(Zwaarte ~ pdq(as.numeric(parameters[i, "p"]), 
                            as.numeric(parameters[i, "d"]), 
                            as.numeric(parameters[i, "q"])) + 
                     PDQ(as.numeric(parameters[i, "P"]), 
                         as.numeric(parameters[i, "D"]), 
                         as.numeric(parameters[i, "Q"]), 
                         period = 7)
            )
      ) %>% #Ook hier wordt weer gekeken naar een forecast van 4 weken en
      forecast(h = 28) %>% #de MAE om het te kunnen vergelijken met de andere modellen
      accuracy(file_test) %>%
      select(MAE) %>%
      pull()
  }, error = function(e) {
    parameters[i, "MAE"] <- NA
  })
}

#De 10 modellen met de laagste MAE worden getoond
parameters %>% drop_na(MAE) %>% slice_min(order_by = MAE, n = 10)

```

```{r TIJD}
#Er wordt gekeken naar hoe de modellen er uit zien. Ook is hierbij alleen het ARIMA model behouden, die het 
#beste resultaat gaf
file_fit <- file_train_sets %>%
  model(
    Mean = MEAN(Zwaarte),
    SNaive = SNAIVE(Zwaarte),
    ETS = ETS(Zwaarte),
    ARIMA = ARIMA(Zwaarte ~ pdq(0,0,2) + PDQ(0,1,1, period = 7))
    )
head(file_fit)
```

```{r fig.width=10, fig.height=50}
file_train_sets <- file_train %>% slide_tsibble(.size = 28, .step = 1, .id = "id")

#Er worden nieuwe forecasts gemaakt. 
#Bij deze forecasts wordt gekeken hoever ze vooruit voorspelde waarde volgens RWS accuraat is
file_fc_mult <- file_train_sets  %>%
  model(
    Mean = MEAN(Zwaarte),
    SNaive = SNAIVE(Zwaarte),
    ANA = ETS(Zwaarte ~ error("A") + trend("N") + season("A")),
    ANN = ETS(Zwaarte ~ error("A") + trend("N") + season("N")),
    ARIMA = ARIMA(Zwaarte ~ pdq(0,1,0) + PDQ(1,1,0, period = 7))
    ) %>%
  forecast(h = 28)

file_fc_mult <- file_fc_mult %>% 
  group_by(.model, id) %>% 
  mutate(h = row_number()) %>% 
  ungroup()

file_fc_mult <- file_fc_mult %>% left_join(filedag, by = "Datum")

file_fc_mult <- file_fc_mult %>% mutate(error = .mean - Zwaarte.y)

file_fc_mult <- file_fc_mult %>% 
  group_by(.model, h) %>% 
  mutate(
    #De boxen van de boxplots lopen van Q1 tot Q3 daarom wordt daarnaar gekeken
    Q1 = quantile(error, 0.25, na.rm = TRUE),
    Q3 = quantile(error, 0.75, na.rm = TRUE),
    
    #Als de box van de boxplot buiten de range valt wordt deze rood gemarkeerd, in plaasts van van zwart
    #Er is hiervoor gekozen en niet voor de stelen meenemen, 
    #sinds anders de modelllen niet eens 1 dag vooruit konden voorspellen
    #Door puur naar de boxen te kijken kunnen de verschillende modellen beter met elkaar worden vergeleken.
    exceeded = ifelse(
      min(Q1, Q3, na.rm = TRUE) < -20000 | max(Q1, Q3, na.rm = TRUE) > 20000, 
      TRUE, 
      FALSE
    )
  ) %>%
  ungroup()

#Er worden plots gemaakt om te tonen hoeveel elk model vooruit kan voorspellen.
file_fc_mult %>%
  ggplot(aes(color = exceeded, x = as.factor(h), y = error)) +
  geom_boxplot() + 
  geom_hline(yintercept = 20000, linetype = "dashed", colour = "blue") + 
  geom_hline(yintercept = -20000, linetype = "dashed", colour = "blue") + 
  scale_color_manual(values = c("red", "red")) + 
  theme(legend.position = "none") +
  labs(x = "Voorspellingshorizon in dagen vanaf 20 februari 2023",
       y = "Absolute fout",
       title = "Absolute fout in de voorspellingshorizon") +
  facet_grid(.model ~ .) +
  coord_cartesian(ylim = c(-60000, 60000))
ggsave("boxplot.png", width = 10, height = 13, dpi = 300)
```

2b) In de onderstaande plot wordt voor 5 modellen getest hoever vooruit de dagelijkse filezwaarte voorspelt kan worden. De voorspellingen mogen niet meer dan 20000 fileminuten maal aantal kilometers afwijken. Wanneer de boxplot rood gekleurd is, valt de voorspelling buiten de grenzen. Een zwarte boxplot geeft aan dat de voorspelling binnen de grenzen zit.

Zoals te zien is in de bovenstaande afbeelding zijn alle voorspellingen van alle modellen invalide. Elk model kan niet verder dan een dag voorspellen, zonder buiten de grens van 20000 kilometer maal minuut te komen. Hierdoor is niet goed te zeggen welk model het het beste doet.


```{r TIJD}
#Er worden nieuwe trainset, testset en trainsets gemaakt. Die overeen komen met de opdracht
#Er is voor deze data gekozen sinds in opdracht 4 gekeken moet worden naar maart 2020. 
#Deze data liggen daar het dichtsbij
file_train_op3 <- filedag %>% filter(Datum >= as.Date('2019-02-18') & Datum < as.Date('2020-02-17'))
file_test_op3 <- filedag %>% filter(Datum >= as.Date('2020-02-17') & Datum < as.Date('2020-02-24'))

file_train_sets3 <- file_train_op3 %>% stretch_tsibble(.init = 29, .step = 1, .id='id')

#Meerdere simpele en ETS modellen worden getest. Die zijn gedeeltelijk gekozen door naar de tijdreeks te kijken
#en gedeeltelijk naar wat het goed deed bij opdracht 2
file_fit2 <- file_train_sets3 %>%
  model(
    Drift = RW(Zwaarte ~ drift()),
    Mean = MEAN(Zwaarte),
    Naive = NAIVE(Zwaarte),
    SNaive = SNAIVE(Zwaarte),
    Holt = ETS(Zwaarte ~ error("A") + trend("A") + season("N")),
    `Holt-Winters` = ETS(Zwaarte ~ error("A") + trend("A") + season("A")),
    ANA = ETS(Zwaarte ~ error("A") + trend("N") + season("A")),
    ANN = ETS(Zwaarte ~ error("A") + trend("N") + season("N")),
    ETS = ETS(Zwaarte)
  )

file_fc2 <- file_fit2 %>% forecast(h =7)

file_fc2 <- file_fc2 %>%
  left_join(file_test_op3, by = "Datum")

file_RMSE <- file_fc2 %>% 
  as_tibble() %>% 
  group_by(id, .model) %>% 
  summarize(id = id, RMSE = sqrt(mean((.mean - Zwaarte.y)^2))) %>% 
  distinct() %>% 
  ungroup()

file_minRMSE <- file_RMSE %>% 
  select(-id) %>% 
  group_by(.model) %>% 
  slice_min(n = 1, RMSE) %>% 
  distinct()


file_minRMSE <- file_minRMSE %>% left_join(file_RMSE, by = "RMSE")


file_minRMSE <- file_minRMSE %>% 
  left_join(file_train_sets3, by = "id")


file_minRMSE %>% 
  group_by(.model.x) %>% 
  filter(Datum == min(Datum)) %>% 
  summarize(Model = .model.x, startmoment = Datum, RMSE = RMSE) %>% 
  select(-.model.x)
```

```{r fig.width=25, fig.height=10}
#Net als bij opdracht 2 wordt gekeken naar de partiële plot om te kijken naar welke range van ARIMA parameters gekeken
#Moet worden.
file_train_op3 %>%
  gg_tsdisplay(Zwaarte, plot_type = 'partial', lag_max = 38*7+1)
```

```{r TIJD}
#Er wordt daarom ook weer gekeken naar de unit roots
file_train_op3 %>% features(Zwaarte, c("unitroot_ndiffs", "unitroot_nsdiffs"))
```

```{r TIJD}

```

```{r TIJD}

```


```{r TIJD}
#De mogelijke parameters
parameters <- expand_grid(p = 0:3, d = 0:1, q = 0:3, P = 0:3, D = 0:1, Q = 0:3)
parameters <- parameters %>% mutate(RMSE = NA)

#Vervolgens passen we elke combinatie van parameters toe op ARIMA()
#en slaan we de bijbehorende RMSE op de testset op
for (i in 1:nrow(parameters)){
  parameters[i,"RMSE"] <- file_train_op3 %>% 
    model(
      ARIMA(Zwaarte ~ pdq(as.numeric(parameters[i,"p"]), 
                      as.numeric(parameters[i,"d"]), 
                      as.numeric(parameters[i,"q"])) + 
                  PDQ(as.numeric(parameters[i,"P"]),
                      as.numeric(parameters[i,"D"]),
                      as.numeric(parameters[i,"Q"]),
                      period = 7)
            )
    ) %>% 
    forecast(h = 7) %>% 
    accuracy(file_test_op3) %>% 
    select(RMSE) %>% 
    pull()
}
slice_min(parameters, order_by = RMSE, n = 10)
```
3A Conclusie:
Met het testen blijkt dat van de relatief simpelere modellen een ETS met MNM ingevuld voor de error, het seizoen en de trend het het beste doet met een RMSE van 11919,49 Als vervolgens ook wordt gekeken naar ARIMA modellen blijkt dat een Arima model met de parameters p=0, d=1 , q=0, P=2, D=0, Q=0 het het beste deed van de univariate modellen. Deze gaf een RMSE van 8558.660.

```{r TIJD}
weer <- read.csv("weer.csv", sep =";")
#Alleen de weerdata wordt meegenomen van de dagen die overeen komen met die uit het filebestand.
weer <- weer %>% 
  filter(YYYYMMDD>20000000) %>%
  filter(YYYYMMDD<20240000)

#van de datum wordt een voor R juiste datumnotering gemaakt, ook krijgen de kolommen makkelijkere namen
weer <-weer %>% 
  mutate(YYYYMMDD = ymd(YYYYMMDD))
colnames(weer) <- c("Datum", "locatie", "meting", "meetwaarde")

#Om het overzichtelijker te maken wordt van de 4 weerstations alleen naar het station in De Bilt gekeken. 
#Dit is het meetstation die het meest centraal in Nederland ligt, daarom is deze gekozen.
#Zijn eerder de files per dag samengevoegd, dus is ook niet meer bekend waar de files zitten
weer <- weer %>% 
  filter(locatie == "De Bilt")
#Vervolgens is de locatiekolom uit de reeks verwijderd omdat deze alleen maar dezelfde waarde had, dus niks meer toevoegde
weer <- weer[-c(2)]
#Vervolgens wordt er een tijdreeks van gemaakt waarbij elke variabele als aparte reeks wordt gezien
weer <- weer %>% 
  as_tsibble(index = Datum, key = c( meting))

#Er is daarna van elke weersvariabele een aparte kolomgemaakt zodat duidelijker en makkelijker naar ze gekeken kan worden
weer <- weer %>% pivot_wider(names_from = meting, values_from = meetwaarde)
weer
```

```{r TIJD}
#De tijdreeksen worden damengeovoegd in 1 dataframe
fileweer <- filedag %>% left_join(weer, by = "Datum")
fileweer
```



```{r TIJD}
#er wordt nu alleen een train set gemaakt, omdat deze wordt gemaakt om te kijken of bij de correlaties van deze tijd moet worden gedifferentiëerd  
file_train_op3B <- fileweer %>% filter(Datum >= as.Date('2019-02-18') & Datum < as.Date('2020-02-17'))

```


```{r TIJD}
kolomnamen <- colnames(file_train_op3B)

# Bereken unit root statistieken voor elke kolom
unitroot_results <- lapply(kolomnamen, function(kolom) {
  file_train_op3B %>%
    select(all_of(kolom)) %>%
    features(!!sym(kolom), list(ndiffs = unitroot_ndiffs, nsdiffs = unitroot_nsdiffs))
})

# Geef de resultatenlijst de juiste namen
names(unitroot_results) <- kolomnamen  

# Combineer de resultaten in één dataframe
unitroot_results_df <- bind_rows(unitroot_results, .id = "variabele")

# Toon de resultaten
print(unitroot_results_df)

```

```{r TIJD}
variabelen_diff <- c(
  "Zwaarte", "DR", "FG", "FHN", "NG", "PN", "Q", "RHXH", "SP", "SQ", "T10N", "TG", "TN", "TX", "UG", "UN", "UNH", "VVN", "VVX", "VVXH")

file_train_diff <- fileweer[-1, ] %>%
  mutate(across(all_of(variabelen_diff), ~ . - lag(.), .names = "diff_{.col}"))

head(file_train_diff)

# Maak een combinatie van variabelen (paren)
var_combinations <- combn(variabelen_diff, 2, simplify = FALSE)

# Bereken de CCF voor elk paar en plot de resultaten
for (kolom in variabelen_diff) {
  if (kolom != "diff_Zwaarte") {  # Zorg ervoor dat Zwaarte niet met zichzelf vergeleken wordt
    ccf_result <- file_train_diff %>%
      CCF(diff_Zwaarte, !!sym(kolom), lag_max = 15)  # CCF tussen Zwaarte en de andere variabele
    
    # Plot en FORCEER het plotten met print()
    plot_ccf <- ccf_result %>%
      autoplot() +
      labs(
        title = paste("Cross-correlation between Zwaarte and", kolom),
        subtitle = "Corrected for non-stationarity"
      )
    
    print(plot_ccf)  # Zorgt ervoor dat alle plots verschijnen
  }
}

```

```{r TIJD}
variabelen_nondiff <- c(
  "Zwaarte", "FHNH", "FHX", "FHXH", "FXX", "FXXH", "PG", "PNH", "PX", "PXH", "RH", "RHX", "T10NH", "TNH", "TXH", "UX", "UXH",
  "VVNH"
) 

file_train_nondiff <- fileweer[-1, ] %>%
  select(all_of(variabelen_nondiff))

head(file_train_nondiff)

# Maak een combinatie van variabelen (paren)
var_combinations <- combn(variabelen_nondiff, 2, simplify = FALSE)

# Bereken de CCF voor elk paar en plot de resultaten
for (kolom in variabelen_nondiff) {
  if (kolom != "Zwaarte") {  # Zorg ervoor dat Zwaarte niet met zichzelf vergeleken wordt
    ccf_result <- file_train_nondiff %>%
      CCF(Zwaarte, !!sym(kolom), lag_max = 15)  # CCF tussen Zwaarte en de andere variabele
    
    # Plot en FORCEER het plotten met print()
    plot_ccf <- ccf_result %>%
      autoplot() +
      labs(
        title = paste("Cross-correlation between Zwaarte and", kolom),
        subtitle = "Corrected for non-stationarity"
      )
    
    print(plot_ccf)  # Zorgt ervoor dat alle plots verschijnen
  }
}
```



Op basis van de CCF plots, worden de lags van een paar variabelen meegenomen. Deze lags moeten worden meegenomen. Niet alle variabelen worden gebruikt en een paar variabelen moeten eerst worden gedifferentieerd.

Hierbij wordt alleen gekeken naar lags tussen 7 en 14. De lags moeten boven de 7 zitten, omdat er in 1 keer 7 dagen vooruit voorspeld moet worden, de lags onder de 7 mogen dus niet gebruikt worden.
Er is voor gekozen om het tot 14 te limiteren, omdat het ten eerste 2 weken, dus 2 seisoenscycli zijn en er vanuit is gegaan dat de significante kruiscorrelaties van na die tijd waarschijnlijk door toeval komen, omdat het weer te veel veranderd om na zo veel tijd echt effect te hebben.

Hieronder worden de niet-gedifferentieerde variabelen gegeven en de bijbehorende lags daarvan:
FHNH (10)
FHX (11)
FHXH (7, 10, 11,12)
FXX (7,8,11)
FXXH (7)
PXH (12)
RHX (8)
TXH (7,13)
VVNH (8,12)


Hieronder worden de wel-gediffentieerde variablen gegeven en de bijhorende lags daarvan:
DR (13)
FG (10)
RHXH (7)
SP (13)
VVX (9)

DR: Neerlagduur in 0,1 uur
FG: Etmaalgemiddelde windsnelheid in 0,1 m/s
RHX: Hoogste uursom van neerslag in 0,1 mm
SP: Percentage van langst mogelijke zonneschijnduur
VVX: Maximum optreden zicht
FHNH: Uurvak waarvan de laagtse uursnelheid is gemeten
FHX: Hoogste uurgemiddelde windsnelheid in 0,1 m/s
FHXH: Uurvak waarvan de hoogste uurgemiddelde windsnelheid is gemeten
FXX: Hoogste windstoot in 0,1 m/s
FXXH: Uurvak waarin hoogste windstoot is gemeten
PXH: Uurvak waarin hoogste luchtdruk is gemeten
TNH: Uurvak waarin minimumtemperatuur is gemeten
VVNH: Uurvak waarin de opgestreden zicht is gemeten

Een aantal variabelen eindigen op een H, dat staat voor een uurvak waarin een bepaalde waarde is gemeten. Deze variabelen zijn niet meegenomen omdat het uurvak waarop iets is gemeten van een paar dagen geleden geen invloed heeft. 


```{r TIJD}


```

```{r TIJD}
#Alleen de gekozen variabelen worden meegenomen verder in de dataframe
fileweer <-fileweer[c("Datum","Zwaarte","FXX", "RHX", "DR", "FG", "SP", "VVX")]
fileweer
```

```{r TIJD}
#De uitbijters worden gezocht om te kunnen kijken of deze verklaard kunnen worden
file_train_op3C <- fileweer %>% filter(Datum >= as.Date('2019-02-18') & Datum < as.Date('2020-02-17'))
file_test_op3C <- fileweer %>% filter(Datum >= as.Date('2020-02-17') & Datum < as.Date('2020-02-24'))

file_decomp_2019 <- file_train_op3C %>%
  model(STL(Zwaarte ~ trend(window =15) +
              season(window = 8), robust = TRUE)) %>% components
file_decomp_2019 %>%
  autoplot()

file_outliers_2019 <- file_decomp_2019 %>%
  filter(remainder %in% boxplot.stats(remainder, coef=3)$out)

file_decomp_2019 %>%
  ggplot(aes(y=0, x = remainder)) +
  geom_boxplot(outlier.color='red', coef =3) +
  geom_label_repel(data=. %>% filter(remainder %in% boxplot.stats(remainder, coef=3)$out),
                   aes(label=as.character(Datum), x = remainder),
                       min.segment.length = 0, direction='both') +
  labs(title= "Boxplot")
```

```{r TIJD}

#Deze uitbijters worden ook als tabel zodat ook naar de waarde in vergelijking met de trend kan worden gekeken.
file_outliers_2019 <- file_decomp_2019 %>%
  filter(remainder %in% boxplot.stats(remainder, coef = 3)$out)

print(file_outliers_2019)
```

```{r TIJD}
#Hiervoor worden 2 spike variabelen aangemaakt.
fileweer <-fileweer %>% 
  mutate(feestdagenlaag = ifelse(Datum %in% ymd(c("2019-04-22", "2019-05-30", "2019-05-30", "2019-06-10", "2019-12-23", "2019-12-24", "2019-12-26", "2019-12-28", "2019-12-31", "2020-01-02")), 1, 0),
         feestdagenhoog = ifelse(Datum %in% ymd(c("2019-04-18", "2019-04-19", "2019-06-07")), 1, 0))

fileweer <- fileweer %>% mutate(lag13DR = lag(DR, 13))
fileweer <- fileweer %>% mutate(lag7FXX = lag(FXX, 7))
fileweer <- fileweer %>% mutate(lag8FXX = lag(FXX, 8))
fileweer <- fileweer %>% mutate(lag11FXX = lag(FXX, 11))
fileweer <- fileweer %>% mutate(lag8RHX = lag(RHX, 8))
fileweer <- fileweer %>% mutate(lag10FG = lag(FG, 10))
fileweer <- fileweer %>% mutate(lag13SP = lag(SP, 13))
fileweer <- fileweer %>% mutate(lag9VVX = lag(VVX, 9))

file_train_op3C <- fileweer %>% filter(Datum >= as.Date('2019-02-18') & Datum < as.Date('2020-02-17'))
file_test_op3C <- fileweer %>% filter(Datum >= as.Date('2020-02-17') & Datum < as.Date('2020-02-24'))

```

Veel van de uitbijters hebben iets te maken met feestdagen.
Vlak voor feestdagen is het vaker drukker. Op de dagen zelf is het rustiger, omdat mensen niet naar werk hoeven


```{r TIJD}
#Er wordt een lineair en dynamisch regressiemodel gefit die de weersvariabelen en de spikevariabelen meenemen
#waarvan wordt uit gegaan dat deze relevant zijn
file_train_sets3c <- file_train_op3C %>% slide_tsibble(.size = 28, .step = 50, .id='id')
file_test_sets3c <- file_train_op3C %>% filter_index('2019-03-18' ~ .) %>% slide_tsibble(.size = 7, .step = 50, .id='id')
file_train_sets3c <- file_train_sets3c %>% filter(id <= max(file_test_sets3c$id))
```

```{r TIJD}
file_weer_fit <- file_train_sets3c %>%
  model(
    linreg = TSLM(Zwaarte ~ season() + lag13DR + lag7FXX + lag8FXX + lag11FXX + lag8RHX + lag10FG + lag13SP + lag9VVX +
                    feestdagenhoog + feestdagenlaag),
    dyn_reg_X = ARIMA(Zwaarte ~ season() + lag13DR + lag7FXX + lag8FXX + lag11FXX + lag8RHX + lag10FG + lag13SP + lag9VVX  + feestdagenhoog + feestdagenlaag)
  )

#file_weer_fc2 <- file_weer_fit %>% forecast(new_data = file_test_sets3c)


file_weer_fc_mult <- file_train_sets3c %>%
      filter(id == 1) %>% 
      model(
        linreg = TSLM(Zwaarte ~ season() + lag13DR + lag7FXX + lag8FXX + lag11FXX + lag8RHX + lag10FG + lag13SP + lag9VVX +
                      feestdagenhoog + feestdagenlaag),
       dyn_reg_X = ARIMA(Zwaarte ~ season() + lag13DR + lag7FXX + lag8FXX + lag11FXX + lag8RHX + lag10FG + lag13SP + lag9VVX 
      )
      ) %>% 
      forecast(new_data = file_test_sets3c %>% filter(id == 1)) %>%
      group_by(id, .model) %>%
      mutate(h = row_number()) %>%
      ungroup() 


for (i in 2:max(file_train_sets3c$id)){
  file_train_sets3c %>% 
    filter(id == i) %>% 
    model(
    linreg = TSLM(Zwaarte ~ season() + lag13DR + lag7FXX + lag8FXX + lag11FXX + lag8RHX + lag10FG + lag13SP + lag9VVX +
                    feestdagenhoog + feestdagenlaag),
    dyn_reg_X = ARIMA(Zwaarte ~ season() + lag13DR + lag7FXX + lag8FXX + lag11FXX + lag8RHX + lag10FG + lag13SP + lag9VVX  + feestdagenhoog + feestdagenlaag)
  ) %>% 
    forecast(new_data = file_test_sets3c %>% filter(id == i)) %>%
    group_by(id, .model) %>%
    mutate(h = row_number()) %>%
    ungroup() %>%
    bind_rows(file_weer_fc_mult) -> file_weer_fc_mult
}





file_weer_fc_mult <- file_weer_fc_mult %>%
  left_join(fileweer, by = "Datum")




file_weer_RMSE <- file_weer_fc_mult %>% 
  as_tibble() %>% 
  group_by(id, .model) %>% 
  summarize(id = id, RMSE = sqrt(mean((.mean - Zwaarte.y)^2))) %>% 
  distinct() %>% 
  ungroup()

file_weer_minRMSE <- file_weer_RMSE %>% 
  select(-id) %>% 
  group_by(.model) %>% 
  slice_min(n = 1, RMSE) %>% 
  distinct()



file_weer_minRMSE

#file_weer_fc <- file_weer_fit %>% forecast(new_data = file_test_op3C)
#accuracy(file_weer_fc, file_test_op3C) %>% select(.model, RMSE) %>% arrange(RMSE)

```


3d)
Hierboven zijn een paar modellen gemaakt om de filezwaarte te voorspellen voor één week in februari 2020. Hiervoor is trainingsdata uit 2019 en een deel uit 2020 gebruikt. Het lineaire regressiemodel met weersvariabelen presteert het beste wat betreft RMSE. Deze is slechts 4994. Bij de univarate modellen doen de ETS-modellen het ook aardig, de beste is een ETS-model dat R zelf heeft gekozen. Dit model heeft voor de parameters M, N en M, en heeft een RMSE van ongeveer 12000. Het beste univariate model was een arima model met de parameters p=0, d=1 , q=0, P=2, D=0, Q=0. Deze gaf een RMSE van 8559.

De modellen met weerdata doen het beter dan de modellen zonder. Hieruit is te halen dat het weer wel degelijk effect heeft op de filezwaarte, zelfs als het van een paar dagen terug is. Dit komt ook overeen met de conclusie die getrokken was bij opdracht 1, sinds de bijzonderheden vaak door weersomstandigheden verklaard konden worden.




```{r TIJD}
file_train_op4 <- fileweer %>% filter(Datum >= as.Date('2019-02-18') & Datum < as.Date('2020-02-24'))
file_test_op4 <- fileweer %>% filter(Datum >= as.Date('2015-03-01') & Datum < as.Date('2015-04-01'))

file_test_op4 <- file_test_op4 %>%
  mutate(Datum = update(Datum, year = 2020)) 

file_train_op4 <- file_train_op4 %>%
  as_tsibble(index = Datum)

file_test_op4 <- file_test_op4 %>%
  as_tsibble(index = Datum)
```

```{r TIJD}
#Er wordt een forecast gemaakt voor de file van maart 2020. Hierin wordt alleen het model meegenomen dat het het beste deed
#Bij opdracht 3. 
file_fit4 <- file_train_op4 %>%
  model(
    linreg = TSLM(Zwaarte ~ season() + lag13DR + lag7FXX + lag8FXX + lag11FXX + lag8RHX + lag10FG + lag13SP + lag9VVX +
                    feestdagenhoog + feestdagenlaag)
  )
file_fc4 <- file_fit4 %>% forecast(new_data = file_test_op4, h= 38)


file_fc4  %>%
  autoplot(level = NULL) +
  labs(
    title = "Voorspelling van filezwaarte in maart 2020",
    y = "Filezwaarte",
    x = "Datum"
  ) +
  guides(colour = guide_legend(title = "Voorspelling maart 2020")) +
  theme_minimal()


```

In de bovenstaande plot is een voorspelling van de dagelijkse filezwaarte over maart 2020 weergegeven, zonder de betrouwbaarheids-intervallen. Ook hierin is goed het weekpatroon terug te vinden. De datums op de assen zijn elk maandagen, welke steeds net na 2 rustige dagen vallen.
Opvallend is dat in de laatste week van maart dit weekpatroon iets afwijkt ten opzichte van de rest. Het model voorspelt op vrijdag 27 maart de hoogste filezwaarte in die week, wat niet ter sprake is bij de andere vrijdagen. Dit kan komen omdat nu vrijwel een maand vooruit wordt voorspelt en het model dan minder accuraat wordt



```{r TIJD}
file_fc4_sim <- file_fit4 %>%
  select(linreg) %>%
  forecast(new_data = file_test_op4, bootstrap = TRUE, times = 10000, level =95)

file_train_op4 %>%
  filter(Datum >= as.Date("2020-03-01")) %>%
  autoplot(Zwaarte) +
  autolayer(file_fc4 %>% filter(.model == 'linreg'),
            level = 95, colour = 'dodgerblue', alpha = 0.5) +
  autolayer(file_fc4_sim, level = 95, colour = 'red', alpha = 0.5) + theme_bw() +
  labs(title = 'Voorspelde dagelijkse filezwaarte in Nederland in kilometer maal minuut',
       x = 'Datum',
       y = 'Filezwaarte',
       subtitle = '95% betrouwbaarheids interval in het rood')

```


In deze plot wordt ook het betrouwbaarheidsinterval voor elke voorspelling gegeven. Deze wordt berekent door de historische gegevens van maart 2015. Voor dit jaar is gekozen omdat de kalender van die maand exact overeenkomt met maart 2020. Het was alleen mogelijk om de voorspelde filezwaarte met de gebootstrapte file-zwaarte van vijf jaar terug te vergelijken als er geen trend is over de vijf jaren. Uit de visualisatie van opgave 1 blijkt dat dit tussen maart 2015 en maart 2020 niet dusdanig het geval is.

Verder opvallend is dat de voorspelde filezwaarte in het weekend soms negatief is. Dit komt omdat de filezwaarte dan erg laag is en het model er dusdanig naast zit dat de voorspelling negatief wordt. In de praktijk zal dit uiteraard nooit voorkomen


De voorspellingen zijn een klein beetje betrouwbaar voor de eerste 3 weken. Uit de intervallen is nog wel het seizoenscomponent van de week te zien, maar de weekenden komen met de betrouwbaarheidsintervallen behoorlijk negatief uit, De betrouwbaarheidsintervallen lijken een marge van 80000 te hebben wat ongeveer 2 keer zo hoog is als hoe de filezwaarte ongeveer wordt voorspeld.
Hierdoor wordt de conclusie getrokken dat de voorspelling wel ergens op slaat, maar is niet heel betrouwbaar is.










Er zijn bronnen gebruikt voor de sneeuwstormen in 2005, 2010 en 2012

bronvermelding:

Van Bernebeek, W. (2024, 27 november). Weerplaza.nl. Infoplaza. Geraadpleegd op 17 januari 2025, van https://www.weerplaza.nl/weerinhetnieuws/extreme-sneeuw-van-25-november-2005/6691 


Van den Broek, D. (2020, 19 september). 8 jaar geleden: veel sneeuw en de koudste nacht van de eeuw. Weer.nl. https://www.weer.nl/nieuws/2020/8-jaar-geleden-veel-sneeuw-en-de-koudste-nacht-van-de-eeuw

Van Wezel, J. (2020, 5 juni). December 2010: koudste decembermaand sinds 1969. Weeronline. https://www.weeronline.nl/nieuws/weeroverzichten-2010-december
