---
title: "Eindopdracht"
author: "Lucas"
date: "2025-01-06"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
#install.packages("ggrepel")
library(ggrepel)
library(scales)
library(tsibble)
library(dplyr)
library(fpp3)
library(fable)
library(ggplot2)
```



```{r TIJD}
files <- read.csv("filedata.csv", sep =";")
```

```{r TIJD}
sum(is.na(files))
max(files$duurMinuten)
min(files$duurMinuten)
str(files)
```


```{r TIJD}
files$zwaarteKmMin <- as.numeric(files$zwaarteKmMin)
files$BeginDatum <- as.Date(files$BeginDatum)
filedag <- aggregate(zwaarteKmMin ~ BeginDatum, data = files, FUN = sum)
alle_datums <- data.frame(BeginDatum = seq(min(as.Date(files$BeginDatum)), 
                                           max(as.Date(files$BeginDatum)), 
                                           by = "day"))
filedag <- merge(alle_datums, filedag, by = "BeginDatum", all.x = TRUE)
filedag$zwaarteKmMin[is.na(filedag$zwaarteKmMin)] <- 0
colnames(filedag) <- c("Datum", "Zwaarte")
filedag <- filedag %>%
  as_tsibble(index = Datum)
filedag
```

```{r}

```



```{r fig.width=20, fig.height=6}
filedag %>%
  autoplot(Zwaarte/60) +
  labs(
    title = "Totale filezwaarte per dag in uren",
    x = "Jaar",
    y = "Aantal uren file"
  ) +
  scale_x_date(
    breaks = seq(from = as.Date("2000-01-01"), to = as.Date("2024-01-01"), by = "1 year"), 
    labels = scales::date_format("%Y"), 
    limits = c(as.Date("2000-01-01"), as.Date("2024-01-01")) 
  ) +
  coord_cartesian(ylim = c(0, 3500)) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) 
```



```{r fig.width=20, fig.height=6}
file_decomp <- filedag %>%model( STL(Zwaarte ~ trend(window = 366) +season(window = "periodic"), robust = TRUE) ) %>% components()
autoplot(file_decomp) +
  labs(
    title = "STL-decompositie van dagelijkse filezwaarte",
    x = "Jaar",
    y = "Filezwaarte"
  )  +
  scale_x_date(
    breaks = seq(from = as.Date("2000-01-01"), to = as.Date("2024-01-01"), by = "1 year"),
    labels = scales::date_format("%Y"),  
    limits = c(as.Date("2000-01-01"), as.Date("2024-01-01")) 
  ) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))  
```

```{r fig.width=20, fig.height=6}
file_decomp_2023 <- filedag %>%
  filter(Datum >= as.Date('2023-01-07') & Datum < as.Date('2023-04-01')) %>%
  model( STL(Zwaarte ~ trend(window = 15) +season(window = "periodic"), robust = TRUE) ) %>% components()

weekends <- data.frame(
  start = seq(as.Date("2023-01-07"), as.Date("2023-04-01"), by = "week"),
  end = seq(as.Date("2023-01-08"), as.Date("2023-04-02"), by = "week")
)

# Plot de data met weekenden gearceerd
autoplot(file_decomp_2023) +
  # Arceer de weekenden
  geom_rect(
    data = weekends, 
    aes(xmin = start, xmax = end, ymin = -Inf, ymax = Inf),
    fill = "blue", alpha = 0.2
  ) +
  labs(
    title = "STL-decompositie van dagelijkse filezwaarte tussen 7 januari en 1 april 2023",
    x = "Week",
    y = "Filezwaarte"
  ) +
  scale_x_date(
    date_breaks = "1 week",         # Zet een label voor elke week
    date_labels = "%Y-%m-%d",      # Formatteer als 'jaar-maand-dag'
    limits = c(as.Date("2023-01-01"), as.Date("2023-04-01")) # Beperk x-as tot specifiek bereik
  ) +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1)
  )

```

1b)   De trend is stijgend tot het jaar 2008, vervolgens dalend tot 2014 en stijgt weer tot 2020. Daarna is er een flinke daling zichtbaar in het jaar 2020. Daarna stijgt het weer. Verder is er ook een overduidelijk seizoenscomponent te zien, waarbij het begin en het einde van het jaar laag is, en in het voorjaar en het najaar hoog is. 

Vervolgens is er gekeken naar een subset van de tijdreeks, namelijk van de eerste 13 weken van 2023 met uitzondering van de eerste week, waarin het nog kerstvakantie was. Dit is gedaan om beter het verloop per week te zien. Hierdoor kunnen we concluderen dat er nog een tweede seizoenscomponent is, die weekelijks is. In de STL decompostite is het weekend blauw gemarkeerd om beter de weken te zien. Dan is te zien dat de dinsdagen en donderdagen steeds het hoogst zijn, maandagen, woensdagen en vrijdagen zijn nog steeds druk maar lager en de weekenden zijn het laagst.

1c)   Er wordt onderscheid gemaakt in gebeurtenissen die invloed hadden voor 1 of enkele dagen en gebeurtenissen voor de langere termijn.
        Er zijn drie pieken van filezwaarte boven de 3000 uur maal kilometer. 
          1. In november 2005 was er een zeer zware sneeuwstorm die tot ongekende files leidde.
          2. December 2010 was een zeer koude maand en halverwege de maand viel een grote hoeveelheid sneeuw in de randstad. De piek was iets lager dan de piek in 2005 ondanks dat er              meer sneeuw viel, maar omdat deze gebeurtenis plaatsvond in december, waar veel mensen al op vakantie waren, viel de piek naar verwachting iets lager uit.
          3. In februari 2012 viel er ook veel sneeuw in Noord-Holland, Utrecht en Friesland. 
        Er waren in deze periode ook gebeurtenissen die invloed hebben op de langere termijn. De twee belangrijkste worden benoemd.
          1. In 2008 begon de financiÃ«le crisis waardoor de welvaart daalde. Daarom nam zeer waarschijnlijk ook het aantal files over de jaren af in plaats van toe.
          2. In 2020 brak het coronavirus uit, waardoor de overheid de bevolking sterk aanraadde om thuis te werken. Ook werden meerdere lockdowns van kracht. Dit leidde tot een flinke maar wel tijdelijk daling van de filezwaarte in Nederland.
        

```{r TIJD}
sd(filedag$Zwaarte)
quantile(filedag$Zwaarte)
IQR(filedag$Zwaarte)
```

2a) de standaarddeviatie van de data is ruim 29000. 20000 is daarom een aardig grote bandbreedte om voorspellingen te maken. Waneer de 37 uitbijters worden verwijderd, is de standaarddeviatie gedaald naar minder dan 20000.


```{r TIJD}
file_outliers <- file_decomp %>%
  filter(remainder %in% boxplot.stats(file_decomp$remainder, coef = 3)$out)
file_cleaned <- file_decomp %>%
  filter(!remainder %in% file_outliers$remainder)
sd_cleaned <- sd(file_cleaned$remainder)
quantiles_cleaned <- quantile(file_cleaned$remainder)
iqr_cleaned <- IQR(file_cleaned$remainder)
sd_cleaned
quantiles_cleaned
iqr_cleaned

```


```{r TIJD}
file_train <- filedag %>% filter(Datum >= as.Date('2022-01-10') & Datum < as.Date('2023-02-20'))
file_test <- filedag %>% filter(Datum >= as.Date('2023-02-20') & Datum < as.Date('2023-03-20'))
```


```{r TIJD}
file_train_sets <- file_train %>% stretch_tsibble(.init = 29, .step = 1, .id='id')
file_fit <- file_train_sets %>%
  model(
    Drift = RW(Zwaarte ~ drift()),
    Mean = MEAN(Zwaarte),
    Naive = NAIVE(Zwaarte),
    SNaive = SNAIVE(Zwaarte)
    )

file_fc <- file_fit %>% forecast(h = 28)

file_fc <- file_fc %>%
  left_join(file_test, by = "Datum")

file_MAE <- file_fc %>%
  as_tibble() %>%
  group_by(id, .model) %>%
  summarize(MAE = mean(abs(.mean - Zwaarte.y), na.rm = TRUE), .groups = "drop")

file_minMAE <- file_MAE %>%
  group_by(.model) %>%
  slice_min(MAE, n = 1, with_ties = FALSE) %>%
  ungroup()

file_minMAE <- file_minMAE %>%
  left_join(file_train_sets, by = "id")

file_minMAE %>%
  group_by(.model) %>%
  filter(Datum == min(Datum)) %>%
  summarize(
    Model = .model,
    startmoment = min(Datum),
    MAE = min(MAE)
  )
```


```{r TIJD}

```

```{r fig.width=20}
file_train %>% gg_tsdisplay(Zwaarte, plot_type = 'partial', lag_max = 77)
```

```{r TIJD}
file_train %>%
  autoplot()
frequency(file_train$Zwaarte)
file_train <- file_train %>%
  mutate(Zwaarte = ts(Zwaarte, frequency = 7))
```

```{r TIJD}
file_train %>% gg_tsdisplay(Zwaarte, plot_type = 'partial', lag_max = 77)
```

```{r TIJD}
file_train %>% features(Zwaarte, c(unitroot_ndiffs, unitroot_nsdiffs))
```


```{r TIJD}
# Beperk parametercombinaties
parameters <- expand_grid(p=0:2, d = 0:1, q = 0:2, P = 0:2, D = 0:1, Q = 0:2)
parameters <- parameters %>% mutate(MAE = NA)

# Voer de grid search uit met foutafhandeling
for (i in 1:nrow(parameters)){
  tryCatch({
    parameters[i, "MAE"] <- file_train %>%
      model(
        ARIMA(Zwaarte ~ pdq(as.numeric(parameters[i, "p"]), 
                            as.numeric(parameters[i, "d"]), 
                            as.numeric(parameters[i, "q"])) + 
                     PDQ(as.numeric(parameters[i, "P"]), 
                         as.numeric(parameters[i, "D"]), 
                         as.numeric(parameters[i, "Q"]), 
                         period = 7)
            )
      ) %>% 
      forecast(h = 28) %>%
      accuracy(file_test) %>%
      select(MAE) %>%
      pull()
  }, error = function(e) {
    parameters[i, "MAE"] <- NA
  })
}

# Toon de top 10 modellen met de laagste MAE
parameters %>% drop_na(MAE) %>% slice_min(order_by = MAE, n = 10)

```

```{r TIJD}
file_fit <- file_train_sets %>%
  model(
    Mean = MEAN(Zwaarte),
    SNaive = SNAIVE(Zwaarte),
    ETS = ETS(Zwaarte),
    ARIMA = ARIMA(Zwaarte ~ pdq(0,0,2) + PDQ(0,1,1, period = 7))
    )
head(file_fit)
```

```{r fig.width=10, fig.height=50}
file_train_sets <- file_train %>% slide_tsibble(.size = 28, .step = 1, .id = "id")

file_fc_mult <- file_train_sets  %>%
  model(
    Mean = MEAN(Zwaarte),
    SNaive = SNAIVE(Zwaarte),
    ANA = ETS(Zwaarte ~ error("A") + trend("N") + season("A")),
    ANN = ETS(Zwaarte ~ error("A") + trend("N") + season("N")),
    ARIMA = ARIMA(Zwaarte ~ pdq(0,1,0) + PDQ(1,1,0, period = 7))
    ) %>%
  forecast(h = 28)

file_fc_mult <- file_fc_mult %>% 
  group_by(.model, id) %>% 
  mutate(h = row_number()) %>% 
  ungroup()

file_fc_mult <- file_fc_mult %>% left_join(filedag, by = "Datum")

file_fc_mult <- file_fc_mult %>% mutate(error = .mean - Zwaarte.y)

file_fc_mult <- file_fc_mult %>% 
  group_by(.model, h) %>% 
  mutate(
    # Bereken Q1 en Q3 (de grenzen van de box)
    Q1 = quantile(error, 0.25, na.rm = TRUE),
    Q3 = quantile(error, 0.75, na.rm = TRUE),
    
    # Als de box (Q1 tot Q3) buiten de grenzen van -20.000 en 20.000 ligt, markeer als 'exceeded'
    exceeded = ifelse(
      min(Q1, Q3, na.rm = TRUE) < -20000 | max(Q1, Q3, na.rm = TRUE) > 20000, 
      TRUE, 
      FALSE
    )
  ) %>%
  ungroup()

file_fc_mult %>%
  ggplot(aes(color = exceeded, x = as.factor(h), y = error)) +
  geom_boxplot() + 
  geom_hline(yintercept = 20000, linetype = "dashed", colour = "blue") + 
  geom_hline(yintercept = -20000, linetype = "dashed", colour = "blue") + 
  scale_color_manual(values = c("black", "red")) + 
  theme(legend.position = "none") +
  labs(x = "Voorspellingshorizon in dagen vanaf 20 februari 2023",
       y = "Absolute fout",
       title = "Absolute fout in de voorspellingshorizon") +
  facet_grid(.model ~ .) +
  coord_cartesian(ylim = c(-60000, 60000))
```

2b) In de bovenstaande plot is de absolute fout weergegeven voor de voorspellingshorizon van 4 weken. De trainingsdata bestaat uit gegegevens tussen maandag 10 januari 2022 en maandag 6 februari 2023. De testdata bestaat uit gegevens tussen maandag 6 februari en maandag 6 maart 2023. De trainingsdata maakt Er zijn vijf modellen gemaakt die voor de testperiode voorspellingen maken.

Het ANA-model is een ETS-model. De ruisterm is additief (A), de trend is afwezig (N) en het seizoenscomponent is ook additief.
Het ANN-model is ook een ETS-model, waarbij 
Verder is er ook een ARIMA-model gefit. Hierin zijn zes parameters: p,d,q, P, D en Q. Deze zijn respectievelijk 0, 1, 0, 1, 1 en 0. Deze optimale waarden van deze variabelen zijn verkregen door middel van een grid search.
Naast de drie complexe modellen zijn ook twee baseline modellen opgesteld. 
Het model dat het gemiddelde volgt (Mean) berekent het gemiddelde van de gegevens van de trainingsdata.
Het Seasonal Naive-model herhaalt het laatste weekpatroon uit de trainingsdata.





```{r TIJD}

file_train_op3 <- filedag %>% filter(Datum >= as.Date('2023-01-02') & Datum < as.Date('2023-12-11'))
file_test_op3 <- filedag %>% filter(Datum >= as.Date('2023-12-11') & Datum < as.Date('2023-12-18'))
file_train_sets3 <- file_train_op3 %>% slide_tsibble(.size = 14, .step = 1, .id = 'id')

file_fit2 <- file_train_sets3 %>%
  model(
    Drift = RW(Zwaarte ~ drift()),
    Mean = MEAN(Zwaarte),
    Naive = NAIVE(Zwaarte),
    SNaive = SNAIVE(Zwaarte),
    Holt = ETS(Zwaarte ~ error("A") + trend("A") + season("N")),
    `Holt-Winters` = ETS(Zwaarte ~ error("A") + trend("A") + season("A")),
    ANA = ETS(Zwaarte ~ error("A") + trend("N") + season("A"))
  )
file_fc2 <- file_fit2 %>% forecast(h =7)

file_fc2 <- file_fc2 %>%
  left_join(file_test_op3, by = "Datum")

file_RMSE <- file_fc2 %>% 
  as_tibble() %>% 
  group_by(id, .model) %>% 
  summarize(id = id, RMSE = sqrt(mean((.mean - Zwaarte.y)^2))) %>% 
  distinct() %>% 
  ungroup()

file_minRMSE <- file_RMSE %>% 
  select(-id) %>% 
  group_by(.model) %>% 
  slice_min(n = 1, RMSE) %>% 
  distinct()

file_minRMSE <- file_minRMSE %>% left_join(file_RMSE, by = "RMSE")

file_minRMSE <- file_minRMSE %>% 
  left_join(file_train_sets3, by = "id")


file_minRMSE %>% 
  group_by(.model.x) %>% 
  filter(Datum == min(Datum)) %>% 
  summarize(Model = .model.x, startmoment = Datum, RMSE = RMSE) %>% 
  select(-.model.x)
```

```{r fig.width=20, fig.height=6}
file_train %>%
  gg_tsdisplay(Zwaarte, plot_type = 'partial', lag_max = 50)
```

```{r TIJD}
file_train_op3 <- filedag %>% filter(Datum >= as.Date('2019-02-18') & Datum < as.Date('2020-02-17'))
file_test_op3 <- filedag %>% filter(Datum >= as.Date('2020-02-17') & Datum < as.Date('2020-02-24'))

file_train_sets3 <- file_train_op3 %>% slide_tsibble(.size = 21, .step = 1, .id = 'id')

file_fit2 <- file_train_sets3 %>%
  model(
    Drift = RW(Zwaarte ~ drift()),
    Mean = MEAN(Zwaarte),
    Naive = NAIVE(Zwaarte),
    SNaive = SNAIVE(Zwaarte),
    Holt = ETS(Zwaarte ~ error("A") + trend("A") + season("N")),
    `Holt-Winters` = ETS(Zwaarte ~ error("A") + trend("A") + season("A")),
    ANA = ETS(Zwaarte ~ error("A") + trend("N") + season("A")),
    ANN = ETS(Zwaarte ~ error("A") + trend("N") + season("N")),
    ETS = ETS(Zwaarte)
  )
file_fc2 <- file_fit2 %>% forecast(h =7)

file_fc2 <- file_fc2 %>%
  left_join(file_test_op3, by = "Datum")

file_RMSE <- file_fc2 %>% 
  as_tibble() %>% 
  group_by(id, .model) %>% 
  summarize(id = id, RMSE = sqrt(mean((.mean - Zwaarte.y)^2))) %>% 
  distinct() %>% 
  ungroup()

file_minRMSE <- file_RMSE %>% 
  select(-id) %>% 
  group_by(.model) %>% 
  slice_min(n = 1, RMSE) %>% 
  distinct()


file_minRMSE <- file_minRMSE %>% left_join(file_RMSE, by = "RMSE")


file_minRMSE <- file_minRMSE %>% 
  left_join(file_train_sets3, by = "id")


file_minRMSE %>% 
  group_by(.model.x) %>% 
  filter(Datum == min(Datum)) %>% 
  summarize(Model = .model.x, startmoment = Datum, RMSE = RMSE) %>% 
  select(-.model.x)
```

```{r fig.width=25, fig.height=10}
file_train_op3 %>%
  gg_tsdisplay(Zwaarte, plot_type = 'partial', lag_max = 38*7+1)
```

```{r TIJD}
file_train_op3 %>% features(Zwaarte, c("unitroot_ndiffs", "unitroot_nsdiffs"))
```

```{r TIJD}

```

```{r TIJD}

```


```{r TIJD}
parameters <- expand_grid(p = 0:3, d = 0:1, q = 0:3, P = 0:3, D = 0:1, Q = 0:3)
parameters <- parameters %>% mutate(RMSE = NA)

# vervolgens passen we elke combinatie van parameters toe op ARIMA()
# en slaan we de bijbehorende RMSE op de testset op
for (i in 1:nrow(parameters)){
  parameters[i,"RMSE"] <- file_train_op3 %>% 
    model(
      ARIMA(Zwaarte ~ pdq(as.numeric(parameters[i,"p"]), 
                      as.numeric(parameters[i,"d"]), 
                      as.numeric(parameters[i,"q"])) + 
                  PDQ(as.numeric(parameters[i,"P"]),
                      as.numeric(parameters[i,"D"]),
                      as.numeric(parameters[i,"Q"]),
                      period = 7)
            )
    ) %>% 
    forecast(h = 7) %>% 
    accuracy(file_test_op3) %>% 
    select(RMSE) %>% 
    pull()
}
slice_min(parameters, order_by = RMSE, n = 10)
```
3A Conclusie:
Met het testen blijkt dat van de relatief simpelere modellen een ETS met MNM ingevuld voor de error, het seizoen en de trend het het beste doet met een RMSE van 11919,49 Als vervolgens ook wordt gekeken naar ARIMA modellen blijkt dat een Arima model met de parameters p=0, d=1 , q=0, P=2, D=0, Q=0. Deze gaf een RMSE van 8558.660.

```{r TIJD}
weer <- read.csv("weer.csv", sep =";")
weer <- weer %>% 
  filter(YYYYMMDD>20000000) %>%
  filter(YYYYMMDD<20240000)

weer <-weer %>% 
  mutate(YYYYMMDD = ymd(YYYYMMDD))
colnames(weer) <- c("Datum", "locatie", "meting", "meetwaarde")

weer <- weer %>% 
  filter(locatie == "De Bilt")
weer <- weer[-c(2)]
weer <- weer %>% 
  as_tsibble(index = Datum, key = c( meting))
weer <- weer %>% pivot_wider(names_from = meting, values_from = meetwaarde)
weer
```

```{r TIJD}
fileweer <- filedag %>% left_join(weer, by = "Datum")
fileweer
```

```{r TIJD}
weer_var <- fileweer %>%
  select(where(is.numeric)) %>%
  select(-all_of("Zwaarte"))

drop <- c("Datum")
weer_var <-weer_var[,!(names(weer_var) %in% drop)]

correlaties <- sapply(names(weer_var), function(var) {
  cor(fileweer[["Zwaarte"]], fileweer[[var]], use = "complete.obs")
})


correlatie_resultaten <- data.frame(
  Variabele = names(correlaties),
  Correlatie = correlaties
)

correlatie_resultaten <- data.frame(
  Variabele = names(correlaties),
  Correlatie = correlaties
)

correlatie_resultaten <- correlatie_resultaten %>%
  arrange(desc(abs(Correlatie)))

print(correlatie_resultaten)
```

Er is gekozen om te kijken naar correlaties van boven de 0,05

De sterkste correlaties zijn de variabelen: "DR", "RH", "UG", "Q", "PN", "PG", "UN", "PX", "RHX", "TX", "TG", "VVX", "SQ", "T10N"
Die betekenen

DR: Neerlagduur in 0,1 uur
RH: Etmaalsom van de neerslag in 0,1mm
UG: Etmaalgemiddede relatieve vochtingheid in %
Q: Globale straling in J/cm^3
PN: Laagste uurwaarde van luchtdruk op zeeniveau in 0,1 hPa
PG: Etmaalgemiddelde van luchtdruk op zeeniveau in 0,1 hPa
UN: Minimum relatieve luchtvochtigheid in %
PX: Hoogste uurwaarde van lucktdruk op zeeniveau in 0,1 hPa
RHX: Hoogste uursom van de neerslag in 0,1mm
TX: Maximum temperatuur in 0,1 graden C
TG: Etmaalgemiddeelde temperatuur in 0,1 graden C
VVX: Maximum optreden zicht
SQ: zonneschijn duur in 0,1 uur
T10N:Minimum grondtemperatuur in 0,1 graden C

Met behulp van redenatie hebben we er voor gekozen deze variabelen niet mee te nemen:
SQ, PX, PG, PN, 


Dus uit correlaties en nadenken hebben de overige weersvariabelen de grootste samenhang met de filezwaarte.

```{r TIJD}
fileweer <-fileweer[c("Datum","Zwaarte","DR", "RH", "UG", "Q", "UN", "RHX", "TX", "TG", "VVX", "T10N")]
```

```{r TIJD}
file_train_op3C %>%
  autoplot()
```

```{r TIJD}
file_decomp_2019 <- file_train_op3C %>%
  model(STL(Zwaarte ~ trend(window =15) +
              season(window = 8), robust = TRUE)) %>% components
file_decomp_2019 %>%
  autoplot()
```

```{r TIJD}
file_outliers_2019 <- file_decomp_2019 %>%
  filter(remainder %in% boxplot.stats(remainder, coef=3)$out)

file_decomp_2019 %>%
  ggplot(aes(y=0, x = remainder)) +
  geom_boxplot(outlier.color='red', coef =3) +
  geom_label_repel(data=. %>% filter(remainder %in% boxplot.stats(remainder, coef=3)$out),
                   aes(label=as.character(Datum), x = remainder),
                       min.segment.length = 0, direction='both') +
  labs(title= "Boxplot")

```

```{r TIJD}
file_outliers_2019 <- file_decomp_2019 %>%
  filter(remainder %in% boxplot.stats(remainder, coef = 3)$out)

# Bekijk de lijst
print(file_outliers_2019)

# Optioneel: schrijf naar een CSV-bestand
write.csv(file_outliers_2019, "outliers_2019.csv", row.names = FALSE)
```

```{r TIJD}
fileweer <-fileweer %>% 
  mutate(feestdagenlaag = ifelse(Datum %in% ymd(c("2019-04-22", "2019-05-30", "2019-05-30,", "2019-06-10", "2019-12-23", "2019-12-24", "2019-12-26", "2019-12-28", "2019-12-31", "2020-01-02")), 1, 0),
         feestdagenhoog = ifelse(Datum %in% ymd(c("2019-04-18", "2019-04-19", "2019-06-07")), 1, 0))

file_train_op3C <- fileweer %>% filter(Datum >= as.Date('2019-02-18') & Datum < as.Date('2020-02-17'))
file_test_op3C <- fileweer %>% filter(Datum >= as.Date('2020-02-17') & Datum < as.Date('2020-02-24'))
```

```{r TIJD}
file_weer_fit <- file_train_op3C %>%
  model(
    linreg = TSLM(Zwaarte ~ season() + trend() + DR + RH + UG + Q + UN + RHX + TG + T10N + 
                    feestdagenhoog + feestdagenlaag),
    dyn_reg_X = ARIMA(Zwaarte ~ season() + trend() + DR + RH + UG + Q + UN + RHX + TG + T10N + 
                    feestdagenhoog + feestdagenlaag)
  )
file_weer_fc <- file_weer_fit %>% forecast(file_test_op3C)
accuracy(file_weer_fc, file_test_op3C) %>% select(.model, RMSE) %>% arrange(RMSE)
```
3d)
Hierboven zijn een paar modellen gemaakt om de filezwaarte te voorspellen voor Ã©Ã©n week in februari 2020. Hiervoor is trainingsdata uit 2019 en een deel uit 2020 gebruikt. De ARIMA-modellen voorspellen de filezwaarte het beste, het beste ARIMA model heeft parameters voor p, d, q, P, D en Q respectievelijk: 0, 1, 0, 2, 0, 0. De kwadratische fout is hier ongeveer 8500. De ETS-modellen doen het ook aardig, de beste is een ETS-model dat R zelf heeft gekozen. Dit model heeft voor de parameters M, N en M, en heeft een RMSE van ongeveer 12000. De modellen waar weerdata wordt meegenomen doen het slechter, ondanks de toegevoegde spike variabelen voor feestdagen. Dit kan komen doordat de weergegevens minder invloed hebben op de files dan verwacht. Deze twee modellen doen het alsnog beter dan de baseline modellen.


```{r TIJD}
file_train_op4 <- filedag %>% filter(Datum >= as.Date('2019-02-16') & Datum < as.Date('2020-03-01'))
```

```{r TIJD}
file_fc4 <- file_train_op4 %>%
  model(
    ARIMA = ARIMA(Zwaarte ~ pdq(0,1,0) + PDQ(2,0,0, period = 7))
  ) %>%
  forecast(h=31)

file_fc4 %>%
  autoplot(level = 95) +  # Alleen de voorspellingen met 95% betrouwbaarheidsinterval
  labs(
    title = "Voorspelling van filezwaarte met 95% betrouwbaarheidsinterval in maart 2020",
    y = "Filezwaarte",
    x = "Datum"
  ) +
  guides(colour = guide_legend(title = "Voorspelling maart 2020")) +
  theme_minimal()
  
```


```{r TIJD}
file_fc4 %>%
  autoplot(level = NULL) +  # Alleen de voorspellingen met 95% betrouwbaarheidsinterval
  labs(
    title = "Voorspelling van filezwaarte in maart 2020",
    y = "Filezwaarte",
    x = "Datum"
  ) +
  guides(colour = guide_legend(title = "Voorspelling maart 2020")) +
  theme_minimal()
```
De voorspellingen lijken niet heel betrouwbaar te zijn, dit is te zien aan het 95% betrouwbaarheidsinterval. Deze toont enorme grenzen aan die zelfs tot onder 0 lopen. In de plot zonder het 95% betrouwbaarheidsinterval is de voorspelling een stuk logischer, al zijn ook hier een aantal dingen moeilijk te verklaren. De weekenden zijn hier goed zichtbaar, dit klopt ook met de kalender van maart 2020. De dinsdagen zijn elke werkweek het laagst, wat niet logisch volgt uit de trainingsdata. Dit lijkt het grootste probleem te zijn. De overige dagen lijken wel logisch voorspelt te worden.

Naast het overduidelijke seizoenscomponent is ook een dalende trend zichtbaar. Dit klopt ook met de gegevens uit de trainingsdata van maart 2019. Wel lijkt de daling in de voorspelling sterker te zijn dan in de trainingsdata.

```{r TIJD}

```

```{r TIJD}

```

```{r TIJD}

```

```{r TIJD}

```

bronnen:
sneeuwstorm 2005: https://www.weerplaza.nl/weerinhetnieuws/extreme-sneeuw-van-25-november-2005/6691/
sneeuwstorm 2010: https://www.weeronline.nl/nieuws/weeroverzichten-2010-december
sneeuwstorm: 2012: 
